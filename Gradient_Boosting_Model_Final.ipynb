{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "import math\n",
    "pd.set_option('display.max_rows', 3000)\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"~/Downloads/Kaggle_Workflow/train.csv\")\n",
    "test = pd.read_csv(\"~/Downloads/Kaggle_Workflow/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Deleting outliers\n",
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<200000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 79)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0] #use this for splitting up all_data later\n",
    "y_train = train.SalePrice.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n",
    "all_data = all_data.drop(labels = 'PoolQC', axis = 1)\n",
    "#all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n",
    "# all_data = all_data.drop(labels = 'MiscFeature', axis = 1)\n",
    "all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n",
    "all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n",
    "all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n",
    "#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "#all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "#    lambda x: x.fillna(x.median()))\n",
    "all_data[\"LotFrontage\"] = all_data[\"LotFrontage\"].fillna(0)\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "for col in ('GarageYrBlt','GarageArea', 'GarageCars'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\n",
    "all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "all_data = all_data.drop(['Utilities'], axis=1)\n",
    "all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "all_data['GrLivArea2'] = (all_data['GrLivArea']**(1/2))\n",
    "all_data = all_data.drop('GrLivArea', axis = 1)\n",
    "all_data['HalfBath2'] = all_data['HalfBath']\n",
    "all_data.loc[all_data['HalfBath'] >= 1,'HalfBath2'] = .5\n",
    "all_data['Bathrooms'] = all_data['FullBath'] + all_data['HalfBath2']\n",
    "all_data = all_data.drop('FullBath', axis = 1)\n",
    "all_data = all_data.drop('HalfBath', axis = 1)\n",
    "all_data = all_data.drop('HalfBath2', axis = 1)\n",
    "all_data['LotArea2'] = np.log(all_data['LotArea']+1)\n",
    "all_data = all_data.drop('LotArea', axis = 1)\n",
    "all_data['LotFrontage'] = all_data['LotFrontage'].astype(int)\n",
    "all_data['LotFrontage2'] = (all_data['LotFrontage']**(1/2))\n",
    "all_data = all_data.drop('LotFrontage', axis = 1)\n",
    "all_data['ShedSF'] = 0\n",
    "all_data.loc[all_data['MiscFeature'] == 'Shed', 'ShedSF'] = all_data['MiscVal']\n",
    "all_data = all_data.drop('MiscFeature', axis = 1)\n",
    "all_data = all_data.drop('MiscVal', axis = 1)\n",
    "all_data = all_data.drop('TotalBsmtSF', axis = 1)\n",
    "all_data = all_data.drop('LowQualFinSF', axis = 1)\n",
    "# #3SsnPorch\n",
    "all_data = all_data.drop('3SsnPorch', axis = 1)\n",
    "# #Alley\n",
    "# #93% of the data is NA\n",
    "all_data = all_data.drop('Alley', axis = 1)\n",
    "# #BldgType\n",
    "# #Very unbalanced\n",
    "all_data = all_data.drop('BldgType', axis = 1)\n",
    "# #BsmtFinType1 and BsmtFinType2\n",
    "# all_data['testBasementFinType'] = all_data['BsmtFinType1'].astype(str).str.cat(\n",
    "#     all_data['BsmtFinType2'].astype(str), sep=' - ')\n",
    "# all_data = all_data.drop('BsmtFinType1', axis = 1)\n",
    "# all_data = all_data.drop('BsmtFinType2', axis = 1)\n",
    "# #Condition2\n",
    "# #99% of the data is Norm\n",
    "all_data = all_data.drop('Condition2', axis = 1)\n",
    "#Fence\n",
    "all_data['HasFence'] = 0\n",
    "all_data.loc[all_data['Fence'] != 'NA','HasFence'] = 1\n",
    "all_data = all_data.drop('Fence', axis = 1)\n",
    "#Garage\n",
    "all_data = all_data.drop('GarageQual', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2917, 69)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('GarageCond','FireplaceQu', 'BsmtQual', 'BsmtCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', #'PoolQC', \n",
    "        'KitchenQual', 'Functional', 'BsmtFinType1', 'BsmtFinType2',\n",
    "        'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', \n",
    "        'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(all_data[c].values)) \n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "# # Check the skew of all numerical features\n",
    "# skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "# print(\"\\nSkew in numerical features: \\n\")\n",
    "# skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "# skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness = skewness[abs(skewness) > 0.75]\n",
    "# print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "# from scipy.special import boxcox1p\n",
    "# skewed_features = skewness.index\n",
    "# lam = 0.15\n",
    "# for feat in skewed_features:\n",
    "#    #all_data[feat] += 1\n",
    "#    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "   \n",
    "# all_data[skewed_features] = np.log1p(all_data[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 195)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso score: 0.1094 (0.0061)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('lasso', Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=1,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best score is without removing logs/skewness (alpha = .0005, score = .1094)\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "score = rmsle_cv(lasso)\n",
    "print(\"lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "lasso.fit(train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 0.1094 (0.0061)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0006, l1_ratio=.8, random_state=3))\n",
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge score: 0.1114 (0.0059)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#best score is without removing logs/skewness (alpha = 11, score = .1157)\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import linear_model\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(), linear_model.Ridge(alpha = 11, random_state=1))\n",
    "score = rmsle_cv(ridge)\n",
    "print(\"ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "#ridge = linear_model.Ridge(alpha = 5)\n",
    "#ridge_scores = cross_val_score(ridge, housing_model, housing_target_train2, scoring='neg_mean_squared_error', cv = 5)\n",
    "#ridge_scores = np.sqrt(-ridge_scores)\n",
    "#ridge_predictions = cross_val_predict(ridge, housing_model, housing_target_train2, cv = 5)\n",
    "#ridge.fit(housing_model, housing_target_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [10, 50, 100], 'gamma': [1e-07, 0.001], 'kernel': ['rbf'], 'epsilon': [1e-05, 0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "parameters = {'kernel':['rbf'], 'C':[10,50,100], 'gamma':[1e-7, 1e-3],'epsilon':[0.00001,0.2]}\n",
    "svc1 = svm.SVR()\n",
    "clf1 = GridSearchCV(svc1, parameters, verbose = 1)\n",
    "clf1.fit(train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 50, 'epsilon': 1e-05, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12226348434957193"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "clf = SVR(kernel = 'rbf', C= 50, gamma = .001, epsilon = 0.00001)\n",
    "svm_cross_scores = cross_val_score(clf, train.values, y_train, cv=5, scoring ='neg_mean_squared_error')\n",
    "final_crossval = np.sqrt(-svm_cross_scores)\n",
    "final_crossval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train.values, y_train)\n",
    "svr_pred2 = clf.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso20_pred = np.expm1(lasso.predict(test.values))\n",
    "Lasso_submission20 = pd.DataFrame({'Id': test_ID, 'SalePrice': lasso20_pred})\n",
    "Lasso_submission20.to_csv('Lasso_submission20.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Getting best alpha for lasso\n",
    "# from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "# from sklearn import linear_model\n",
    "\n",
    "# def rmse_cv(model):\n",
    "#     rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "#     return(rmse)\n",
    "\n",
    "# alphas = [0.0005, 0.001]\n",
    "# cv_lasso = [rmse_cv(linear_model.Lasso(alpha = alpha)).mean() for alpha in alphas]\n",
    "\n",
    "# cv_lasso = pd.Series(cv_lasso, index = alphas)\n",
    "# cv_lasso.plot(title = \"Validation\")\n",
    "# plt.xlabel(\"alpha\")\n",
    "# plt.ylabel(\"rmse\")\n",
    "# #alpha = 63 is the best option\n",
    "# cv_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bayesian Optimization\n",
    "#Parameter tuning using Bayesian Optimization\n",
    "#from bayes_opt import BayesianOptimization\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "#from sklearn import ensemble\n",
    "#def gbcv(n_estimators, learning_rate, max_depth, min_samples_leaf, min_samples_split, subsample):\n",
    "#    return cross_val_score(\n",
    "#        ensemble.GradientBoostingRegressor(\n",
    "#        n_estimators = int(n_estimators),\n",
    "#        learning_rate = float(learning_rate),\n",
    "#        max_depth = int(max_depth),\n",
    "#        min_samples_leaf = int(min_samples_leaf),\n",
    "#        min_samples_split = int(min_samples_split),\n",
    "#        subsample = float(subsample),\n",
    "#        random_state = 42),\n",
    "#        train, y_train, 'neg_mean_squared_error', cv = 5\n",
    "#    ).mean()\n",
    "#\n",
    "#gbBo = BayesianOptimization(gbcv,\n",
    "#                            {'n_estimators' : (1000, 10000),\n",
    "#                             'learning_rate' : (.01, .1),\n",
    "#                             'max_depth' : (1,10),\n",
    "#                             'min_samples_leaf' : (1,20),\n",
    "#                             'min_samples_split' : (5,25),\n",
    "#                             'subsample' : (1),\n",
    "#                            }\n",
    "#                            )\n",
    "#\n",
    "#gbBo.maximize(n_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gbBo.res['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost1 = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.0465,\n",
    "                                   max_depth=2, max_features='sqrt',\n",
    "                                   min_samples_leaf=3, min_samples_split=18, \n",
    "                                   loss='huber', random_state = 5)\n",
    "#GBoost1 = GradientBoostingRegressor(n_estimators=7000, learning_rate=0.005,\n",
    "#                                   max_depth=20, max_features='sqrt',\n",
    "#                                   min_samples_leaf=5, min_samples_split=30, \n",
    "#                                   loss='huber', random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting1 score: 0.1099 (0.0086)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost1)\n",
    "print(\"Gradient Boosting1 score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost1.fit(train.values, y_train)\n",
    "GB_pred = np.expm1(GBoost1.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBSubmission = pd.DataFrame({ 'Id': test_ID,\n",
    "                            'SalePrice': y_pred })\n",
    "GBSubmission.to_csv(\"GBSubmission_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_feature_importance = GBoost1.feature_importances_\n",
    "gb_feature_importance = 100.0 * (gb_feature_importance / gb_feature_importance.max())\n",
    "#pyplot.bar(range(len(GBoost1.feature_importances_)), GBoost1.feature_importances_)\n",
    "#pyplot.show()\n",
    "feat_imp = pd.Series(GBoost1.feature_importances_, train.columns).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENet.fit(train.values, y_train)\n",
    "ENet_pred = np.expm1(ENet.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENetSubmission = pd.DataFrame({ 'Id': test_ID,\n",
    "                            'SalePrice': y_pred })\n",
    "ENetSubmission.to_csv(\"ENetSubmission_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#clf = SVR(kernel = 'rbf', C= 10, gamma = .001, epsilon = 0.00005)\n",
    "#svm_cross_scores = cross_val_score(clf, housing_model, housing_target_train2, cv=5, scoring ='neg_mean_squared_error')\n",
    "#final_crossval = np.sqrt(-svm_cross_scores)\n",
    "#final_crossval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR score: 0.3958 (0.0167)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "SVR = make_pipeline(SVR(kernel = 'rbf', C = 100, gamma = 0.001, epsilon = 0.0001))\n",
    "score = rmsle_cv(SVR)\n",
    "print(\"SVR score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVR.fit(train.values, y_train)\n",
    "svr_pred = np.expm1(SVR.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVRSubmission = pd.DataFrame({ 'Id': test_ID,\n",
    "                            'SalePrice': y_pred })\n",
    "SVRSubmission.to_csv(\"SVRSubmission_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RobustScaler(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "parameters = {'kernel':['rbf'], 'C':[100,500,1000], 'gamma':[1e-3, 1e-1],'epsilon':[0.00001,0.0001]}\n",
    "svc1 = svm.SVR()\n",
    "clf1 = GridSearchCV(svc1, parameters, verbose = 1)\n",
    "clf1.fit(RobustScaler(train.values), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso.fit(train.values, y_train)\n",
    "lasso_pred = np.expm1(lasso.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lassoSubmission = pd.DataFrame({ 'Id': test_ID,\n",
    "                            'SalePrice': y_pred })\n",
    "lassoSubmission.to_csv(\"lassoSubmission_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting best alpha for ridge\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import linear_model\n",
    "\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "alphas = [.1,.5,1,2]\n",
    "cv_ridge = [rmse_cv(linear_model.Ridge(alpha = alpha)).mean() for alpha in alphas]\n",
    "\n",
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot(title = \"Validation\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")\n",
    "#alpha = 5 is the best option\n",
    "cv_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lasso_pred*(1/4) + svr_pred*(1/4) + GB_pred*(1/4) + ENet_pred*(1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(y_pred)\n",
    "print(\"ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_pred.fit(train.values, y_train)\n",
    "#avg_pred = np.expm1(y_pred.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avgSubmission = pd.DataFrame({ 'Id': test_ID,\n",
    "                            'SalePrice': y_pred })\n",
    "avgSubmission.to_csv(\"Submission_avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
